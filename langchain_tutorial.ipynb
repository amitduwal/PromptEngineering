{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in d:\\code\\promptengineering_langchain\\env\\lib\\site-packages (0.1.9)\n",
      "Requirement already satisfied: openai in d:\\code\\promptengineering_langchain\\env\\lib\\site-packages (1.12.0)\n",
      "Requirement already satisfied: langchain-openai in d:\\code\\promptengineering_langchain\\env\\lib\\site-packages (0.0.7)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.21 in d:\\code\\promptengineering_langchain\\env\\lib\\site-packages (from langchain) (0.0.24)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in d:\\code\\promptengineering_langchain\\env\\lib\\site-packages (from langchain) (3.9.3)\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1.26 in d:\\code\\promptengineering_langchain\\env\\lib\\site-packages (from langchain) (0.1.27)\n",
      "Requirement already satisfied: requests<3,>=2 in d:\\code\\promptengineering_langchain\\env\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\\code\\promptengineering_langchain\\env\\lib\\site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in d:\\code\\promptengineering_langchain\\env\\lib\\site-packages (from langchain) (0.1.9)\n",
      "Requirement already satisfied: numpy<2,>=1 in d:\\code\\promptengineering_langchain\\env\\lib\\site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in d:\\code\\promptengineering_langchain\\env\\lib\\site-packages (from langchain) (1.10.11)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in d:\\code\\promptengineering_langchain\\env\\lib\\site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in d:\\code\\promptengineering_langchain\\env\\lib\\site-packages (from langchain) (2.0.27)\n",
      "Requirement already satisfied: PyYAML>=5.3 in d:\\code\\promptengineering_langchain\\env\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in d:\\code\\promptengineering_langchain\\env\\lib\\site-packages (from langchain) (0.6.4)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in d:\\code\\promptengineering_langchain\\env\\lib\\site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\code\\promptengineering_langchain\\env\\lib\\site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in d:\\code\\promptengineering_langchain\\env\\lib\\site-packages (from openai) (4.3.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in d:\\code\\promptengineering_langchain\\env\\lib\\site-packages (from openai) (4.10.0)\n",
      "Requirement already satisfied: tqdm>4 in d:\\code\\promptengineering_langchain\\env\\lib\\site-packages (from openai) (4.66.2)\n",
      "Requirement already satisfied: sniffio in d:\\code\\promptengineering_langchain\\env\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in d:\\code\\promptengineering_langchain\\env\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.5.2 in d:\\code\\promptengineering_langchain\\env\\lib\\site-packages (from langchain-openai) (0.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\code\\promptengineering_langchain\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in d:\\code\\promptengineering_langchain\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\code\\promptengineering_langchain\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\code\\promptengineering_langchain\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\code\\promptengineering_langchain\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in d:\\code\\promptengineering_langchain\\env\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
      "Requirement already satisfied: idna>=2.8 in d:\\code\\promptengineering_langchain\\env\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in d:\\code\\promptengineering_langchain\\env\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.8.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in d:\\code\\promptengineering_langchain\\env\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.0)\n",
      "Requirement already satisfied: certifi in d:\\code\\promptengineering_langchain\\env\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\code\\promptengineering_langchain\\env\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\code\\promptengineering_langchain\\env\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\code\\promptengineering_langchain\\env\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in d:\\code\\promptengineering_langchain\\env\\lib\\site-packages (from langchain-core<0.2,>=0.1.26->langchain) (23.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in d:\\code\\promptengineering_langchain\\env\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain) (3.9.15)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\code\\promptengineering_langchain\\env\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\code\\promptengineering_langchain\\env\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in d:\\code\\promptengineering_langchain\\env\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in d:\\code\\promptengineering_langchain\\env\\lib\\site-packages (from tiktoken<1,>=0.5.2->langchain-openai) (2023.12.25)\n",
      "Requirement already satisfied: colorama in d:\\code\\promptengineering_langchain\\env\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in d:\\code\\promptengineering_langchain\\env\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the 'D:\\Code\\PromptEngineering_Langchain\\env\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain openai langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", openai_api_key=os.getenv(\"OPENAI_API_KEY\"), temperature=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Langsmith, as a language services provider, can assist with testing by providing translation and localization services for different language versions of the software or product being tested. This can help ensure that the product works properly in different languages and dialects. Langsmith can also provide linguistic validation and cultural adaptation testing to ensure the product is appropriate and effective for specific target audiences. Additionally, Langsmith can support user acceptance testing by providing multilingual testers who can test the product in different languages and provide feedback on its usability and functionality.')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"how can langsmith help with testing?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are world class technical documentation writer.\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"LangSmith can greatly help with testing by providing a controlled environment for developers and QA testers to run automated tests with dynamically generated content. This allows for comprehensive testing coverage without the need for manual data entry or setup.\\n\\nAdditionally, LangSmith can be used to quickly set up localized testing environments, reducing the testing time required for each locale. This is especially useful when testing language-specific features or functionality in an application.\\n\\nUsing LangSmith's powerful API, testers can integrate automated tests directly into their existing testing frameworks and pipelines, streamlining the testing process and ensuring efficient and reliable testing.\\n\\nOverall, LangSmith simplifies testing efforts, accelerates testing cycles, and improves overall testing accuracy by providing a versatile platform for automated test data generation and localization testing.\")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"how can langsmith help with testing?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The output of a ChatModel (and therefore, of this chain) is a message. \n",
    "# However, it's often much more convenient to work with strings. Let's add a simple output parser to convert the chat message to a string.\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Langsmith is a powerful tool that can greatly assist in the testing process by enabling language analysis. Some ways in which Langsmith can help with testing include:\\n\\n1. Detecting language variants: Langsmith can identify different language variants, dialects, and styles, helping in creating test datasets that are representative of diverse language usage.\\n\\n2. Identifying translation errors: Langsmith can spot inaccuracies in translations, flagging any mismatches in syntax or semantics that could impact the quality of an application or content.\\n\\n3. Checking text coherence: Langsmith can verify the coherence and logical consistency of text, ensuring that user interfaces and content set for testing are clear and comprehensible.\\n\\n4. Automating linguistic testing tasks: Langsmith can automate certain linguistic testing tasks, saving time and effort for QA teams while ensuring thorough language analysis for validation.\\n\\n5. Enhancing internationalization testing: Langsmith can provide insights into language-specific features and requirements, supporting the testing of applications in multiple languages and helping businesses achieve international success.\\n\\nOverall, by integrating Langsmith into the testing process, teams can benefit from enhanced linguistic capabilities that improve the quality and accuracy of their testing efforts.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"how can langsmith help with testing?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: content='The Seven Wonders of World are:\\n\\n1. Great Wall of China\\n2. Petra, Jordan\\n3. The Colosseum, Italy\\n4. Machu Picchu, Peru\\n5. Chichen Itza, Mexico\\n6. Taj Mahal, India\\n7. Christ the Redeemer, Brazil'\n"
     ]
    }
   ],
   "source": [
    "# Basic Example of a Prompt.\n",
    "response = llm.invoke(\"What are the 7 wonders of the world?\")\n",
    "print(f\"Response: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Templated Prompt: Human: List 3 cooking recipe ideas italian cuisine (name only).\n",
      "Response: content='1. Spaghetti aglio e olio\\n2. Margherita pizza\\n3. tiramisu'\n"
     ]
    }
   ],
   "source": [
    "# Basic Example of a Prompt Template.\n",
    "prompt_template = ChatPromptTemplate.from_template(\n",
    "    \"List {n} cooking recipe ideas {cuisine} cuisine (name only).\"\n",
    ")\n",
    "prompt = prompt_template.format(n=3, cuisine=\"italian\")\n",
    "print(f\"Templated Prompt: {prompt}\")\n",
    "\n",
    "response = llm.invoke(prompt)\n",
    "print(f\"Response: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Response Parser\n",
    "- formatting responses\n",
    "- structured output\n",
    "\n",
    "ex: Movie\n",
    "- title: str\n",
    "- genre: list[str]\n",
    "- year: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Movie(BaseModel):\n",
    "    title: str = Field(description=\"movie title\")\n",
    "    genre: list[str] = Field(description=\"movie genre\")\n",
    "    year: int = Field(description=\"year of relase\")\n",
    "    \n",
    "parser = PydanticOutputParser(pydantic_object=Movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"title\": {\"title\": \"Title\", \"description\": \"movie title\", \"type\": \"string\"}, \"genre\": {\"title\": \"Genre\", \"description\": \"movie genre\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}, \"year\": {\"title\": \"Year\", \"description\": \"year of relase\", \"type\": \"integer\"}}, \"required\": [\"title\", \"genre\", \"year\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prompt_template_text = \"\"\"\n",
    "Response with a movie recommendation based on the query:\\n\n",
    "{format_instructions}\\n\n",
    "{query}\n",
    "\"\"\"\n",
    "\n",
    "format_instructions = parser.get_format_instructions()\n",
    "print(format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Code\\PromptEngineering_Langchain\\env\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `predict` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "``` \n",
      "{\n",
      "  \"title\": \"Con Air\",\n",
      "  \"genre\": [\"Action\", \"Crime\", \"Thriller\"],\n",
      "  \"year\": 1997\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "prompt_template = ChatPromptTemplate.from_template(\n",
    "    prompt_template_text\n",
    ")\n",
    "\n",
    "prompt = prompt_template.format(query=\"A 90s movie with Nicolas Cage.\", format_instructions=format_instructions)\n",
    "text_output = llm.predict(prompt)\n",
    "print(text_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title='Con Air' genre=['Action', 'Crime', 'Thriller'] year=1997\n"
     ]
    }
   ],
   "source": [
    "parsed_output = parser.parse(str(text_output))\n",
    "print(parsed_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title='Face/Off' genre=['Action', 'Crime', 'Sci-Fi'] year=1997\n"
     ]
    }
   ],
   "source": [
    "# Using LCEL\n",
    "chain = prompt_template | llm | parser\n",
    "response = chain.invoke({\"query\": \"A 90s movie with Nicolas Cage.\", \"format_instructions\": format_instructions})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Chains\n",
    " Chaining prompts, input of a prompt depends on the output of another prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_1 = \"\"\"\n",
    "Come up with a short plot synopsis summary (2-3 lines) for a {genre} movie.\n",
    "\"\"\"\n",
    "\n",
    "prompt_2 = \"\"\"\n",
    "Suggest 5 movie title ideas for this movie: \\n\\n {synopsis}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain, SequentialChain\n",
    "\n",
    "p1_template = ChatPromptTemplate.from_template(prompt_1)\n",
    "chain_1 = LLMChain(llm=llm, prompt=p1_template, output_key=\"synopsis\")\n",
    "\n",
    "p2_template = ChatPromptTemplate.from_template(prompt_2)\n",
    "chain_2 = LLMChain(llm=llm, prompt=p2_template, output_key=\"titles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Code\\PromptEngineering_Langchain\\env\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Output: {'genre': 'comedy', 'synopsis': 'Two friends launch a scheme to make it big by selling exotic seaweed, but when their product turns out to be hazardous instead after endless mishaps and mistaken identity, they must scramble to maintain their friendship and reputation.', 'titles': '1. \"Tangled Seaweed Scandal\" \\n2. \"Salty Business: The Seaweed Saga\" \\n3. \"Into the Deep: A Seaweed Salesmanship Story\" \\n4. \"Seaweed Mishaps and Mischief\" \\n5. \"Underwater Entrepreneurs: The Seaweed Fiasco\"'}\n"
     ]
    }
   ],
   "source": [
    "complex_chain = SequentialChain(\n",
    "    chains=[chain_1, chain_2],\n",
    "    input_variables=[\"genre\"],\n",
    "    output_variables=[\"synopsis\", \"titles\"],\n",
    "    verbose=True,\n",
    ")\n",
    "output = complex_chain({\"genre\": \"comedy\"})\n",
    "print(f\"Output: {output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AGENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numexpr in d:\\code\\promptengineering_langchain\\env\\lib\\site-packages (2.9.0)\n",
      "Requirement already satisfied: google-search-results in d:\\code\\promptengineering_langchain\\env\\lib\\site-packages (2.4.2)\n",
      "Requirement already satisfied: numpy>=1.13.3 in d:\\code\\promptengineering_langchain\\env\\lib\\site-packages (from numexpr) (1.26.4)\n",
      "Requirement already satisfied: requests in d:\\code\\promptengineering_langchain\\env\\lib\\site-packages (from google-search-results) (2.31.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\code\\promptengineering_langchain\\env\\lib\\site-packages (from requests->google-search-results) (2024.2.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\code\\promptengineering_langchain\\env\\lib\\site-packages (from requests->google-search-results) (3.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\code\\promptengineering_langchain\\env\\lib\\site-packages (from requests->google-search-results) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\code\\promptengineering_langchain\\env\\lib\\site-packages (from requests->google-search-results) (2.2.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the 'D:\\Code\\PromptEngineering_Langchain\\env\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install numexpr google-search-results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMMathChain\n",
    "# Chain that interprets a prompt and executes python code to do math.\n",
    "llm_math_chain = LLMMathChain.from_llm(llm=llm, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# google search api\n",
    "from langchain.utilities import SerpAPIWrapper\n",
    "os.environ[\"SERPAPI_API_KEY\"] = os.getenv(\"SERP_API_KEY\")\n",
    "search = SerpAPIWrapper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools\n",
    "Tools are interfaces that an agent can use to interact with the world.\n",
    "They combine a few things:\n",
    "\n",
    "- The name of the tool\n",
    "- A description of what the tool is\n",
    "- JSON schema of what the inputs to the tool are\n",
    "- The function to call\n",
    "- Whether the result of a tool should be returned directly to the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"search\",\n",
    "        description=\"Search for information Google.\",\n",
    "        func=search.run,\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"calculator\",\n",
    "        description=\"Use this tool to calculate the difference between numbers.\",\n",
    "        func=llm_math_chain.run,\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "# The MessagesPlaceholder serves as a dynamic content placeholder within the chat prompt template. \n",
    "# It's designed to be replaced by actual content at runtime. \n",
    "# The variable_name=\"agent_scratchpad\" parameter specifies the name of the variable that will be replaced with the actual content generated \n",
    "# or used by the agent during its execution.\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `search` with `population of usa`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m{'type': 'population_result', 'place': 'United States', 'population': '331.9 million', 'year': '2021'}\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `search` with `population of uk`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m{'type': 'population_result', 'place': 'United Kingdom', 'population': '67.33 million', 'year': '2021'}\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `calculator` with `331900000-67330000`\n",
      "\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new LLMMathChain chain...\u001b[0m\n",
      "331900000-67330000\u001b[32;1m\u001b[1;3m```text\n",
      "331900000-67330000\n",
      "```\n",
      "...numexpr.evaluate(\"331900000-67330000\")...\n",
      "\u001b[0m\n",
      "Answer: \u001b[33;1m\u001b[1;3m264570000\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mAnswer: 264570000\u001b[0m\u001b[32;1m\u001b[1;3mThe population difference between the United States ðŸ‡ºðŸ‡¸ and the United Kingdom ðŸ‡¬ðŸ‡§ is approximately 264,570,000.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is the population difference between ðŸ‡ºðŸ‡¸ and ðŸ‡¬ðŸ‡§?',\n",
       " 'output': 'The population difference between the United States ðŸ‡ºðŸ‡¸ and the United Kingdom ðŸ‡¬ðŸ‡§ is approximately 264,570,000.'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.utils.function_calling import convert_to_openai_function\n",
    "\n",
    "from langchain.agents.format_scratchpad import format_to_openai_functions\n",
    "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser\n",
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "# Convert a raw function/class to an OpenAI function.\n",
    "llm_with_tools = llm.bind(functions=[convert_to_openai_function(t) for t in tools])\n",
    "\n",
    "# Define the agent schema.\n",
    "agent_schema = {\n",
    "    \"input\": lambda x: x[\"input\"],\n",
    "    \"agent_scratchpad\": lambda x: format_to_openai_functions(x[\"intermediate_steps\"]),\n",
    "}\n",
    "# format to openai functions converts (AgentAction, tool output) tuples into FunctionMessages.\n",
    "# Returns list of messages to send to the LLM for the next prediction\n",
    "\n",
    "agent = agent_schema | prompt | llm_with_tools | OpenAIFunctionsAgentOutputParser()\n",
    "\n",
    "# Create an agent executor. Agent that is using tools.\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "agent_executor.invoke({\"input\": \"What is the population difference between ðŸ‡ºðŸ‡¸ and ðŸ‡¬ðŸ‡§?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See COHERE API"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
